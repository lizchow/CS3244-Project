{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "cs4248_logistic_regression.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IS0JjqTEGFNv"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# load data\n",
    "fulltrain = pd.read_csv(\"fulltrain.csv\", names=['label', 'text'])\n",
    "balancedtest = pd.read_csv(\"balancedtest.csv\", names=['label', 'text'])\n",
    "\n",
    "# Print number of rows per dataset\n",
    "print(f\"fulltrain:  Loaded {len(fulltrain.index)} rows\")\n",
    "print(f\"balancedtest: Loaded {len(balancedtest.index)} rows\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niRr_A6rGWtw",
    "outputId": "85ab03e1-009d-4e45-8ee3-7c56cce4d32d"
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fulltrain:  Loaded 48854 rows\n",
      "balancedtest: Loaded 3000 rows\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# process training data\n",
    "trainX = fulltrain['text']\n",
    "trainY = fulltrain['label']\n",
    "\n",
    "# feature engineering, tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(trainX)\n",
    "trainX = vectorizer.transform(trainX)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tFFowulGYQ6",
    "outputId": "7a2268e9-ea22-4e30-a0f1-f96a407c6edb"
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48854, 229597)\n",
      "(48854,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# fit model based on test data, \n",
    "# params are chosen based on hyperparam tuning using GridSearchCV from sklearn\n",
    "# default max_iter leads to underfit, thus set to 5000\n",
    "model = LogisticRegression(C=10, penalty='l2', solver='liblinear', max_iter=5000)\n",
    "model.fit(trainX, trainY)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrSsbMp-Gsdm",
    "outputId": "40f31c3b-ae8d-4751-8547-7286f544f3c9"
   },
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=10, max_iter=5000, solver='liblinear')"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# process test data\n",
    "testX = balancedtest['text']\n",
    "testY = balancedtest['label']\n",
    "testX = vectorizer.transform(testX)"
   ],
   "metadata": {
    "id": "3EjIW2siGxir"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# test model\n",
    "result = model.predict(testX)\n",
    "print(classification_report(testY, result))\n",
    "print(f1_score(y_pred=result, y_true=testY,average = \"macro\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9A7sfgvGzu6",
    "outputId": "41ca46e7-77f6-4137-8011-f84aab9ac0ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.80      0.83       750\n",
      "           2       0.82      0.39      0.53       750\n",
      "           3       0.57      0.83      0.68       750\n",
      "           4       0.80      0.93      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.72      3000\n",
      "weighted avg       0.77      0.74      0.72      3000\n",
      "\n",
      "0.7247357875908803\n"
     ]
    }
   ]
  }
 ]
}